{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CellProfiling  in Python\n",
    "\n",
    "A high-throughput screening analysis pipeline, similar to what you would do in CellProfiler, implemented in Python.\n",
    "\n",
    "Aims: \n",
    "\n",
    "* create an image analysis pipeline for batch processing, somewhat similar to running Cellprofiler\n",
    "* do some statistical analysis and create interactive visualizations using holoviews\n",
    "* introduce pandas data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# High Throughput Screening Workflow\n",
    "\n",
    "<img src=\"./Illustrations/HTMPipeline_alt.png\" height=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sample images\n",
    "Images are a subset of dataset BBBC022 from the [Broad Bioimage Benchmark Collection](https://data.broadinstitute.org/bbbc/)\n",
    "\n",
    "The following description of the dataset is from their website (https://data.broadinstitute.org/bbbc/BBBC022/):\n",
    "\n",
    "Description of the biological application\n",
    "Phenotypic profiling attempts to summarize multiparametric, feature-based analysis of cellular phenotypes of each sample so that similarities between profiles reflect similarities between samples. This image set provides a basis for testing image-based profiling methods wrt. to their ability to distinguish the effects of small molecules.\n",
    "\n",
    "Images\n",
    "The images are of U2OS cells treated with each of 1600 known bioactive compounds and labeled with six labels that characterize seven organelles (the “Cell Painting” assay).\n",
    "\n",
    "This pilot experiment consists of 20 plates. Each plate has 384 wells and each well has 9 fields of view for a total of 69,120 fields of view. Each field was imaged in five channels (detection wavelengths), and each channel is stored as a separate, grayscale image file, so there are 345,600 image files in 16-bit TIFF format.\n",
    "\n",
    "The images are provided in 100 zip archive files, one for each combination of plate and channel. There is a list of the URLs of all 100 files to facilitate downloading the entire image set in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pathlib\n",
    "import re\n",
    "import numpy as np\n",
    "import mahotas # see other Image Analysis Packages !\n",
    "import scipy.ndimage.morphology\n",
    "import pandas as pd\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#files = glob.glob(\"/Users/volker/Downloads/BroadData/**/*.tif\", recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dealing with filenames in python, the 2018 way \n",
    "\n",
    "Consider using `pathlib` instead of `os.path`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Set our base folder (adjust this to the path where your images are)\n",
    "folder = pathlib.Path(\"/Users/volker/Downloads/BroadData/for_course/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# rglob \"recursive\" (i.e. look in subfolders) \"glob\" (search for files) according to a pattern (here \"*.tif\")\n",
    "files =  folder.rglob(\"*.tif\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# But what is this thing ? Doesn't look like a list of filenames !\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It's a _generator_ object ... you will find these get returned quite often in Python 3 (also in places where you would have gotten back a list in python 2.7). \n",
    "\n",
    "\n",
    "You can convert the generator object into a list using `list()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "allfiles = list(files)\n",
    "allfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now try to run the above cell again ... What's happening?\n",
    "\n",
    "The generator generates each item only once !\n",
    "\n",
    "So what is the benefit ?\n",
    "\n",
    "**only compute when needed** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "files =  folder.rglob(\"*.tif\")\n",
    "import itertools\n",
    "first_5_files = itertools.islice(files, 5)\n",
    "first_5_files = list(first_5_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#%%timeit \n",
    "files =  folder.rglob(\"*.tif\")\n",
    "first_5_files = list(files)[:5]\n",
    "first_5_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extracting Metadata from Path/File names with regular expressions\n",
    "\n",
    "In many cases, you will find some Metadata that is related to your screen embedded in the file names of the images.\n",
    "Therefore we need to extract this information from the images we analyze.\n",
    "\n",
    "_Regular expressions_ are a flexible tool for analyzing/splitting strings that are built according to some regular pattern. If you google for \"python regular expressions\" you will find plenty of documentation and examples on how to use them. \n",
    "\n",
    "As regular expressions have a large number of building blocks that may be difficult to remember, it is nice to have a cheat sheet. There is a great online tool for creating and debugging regular expressions with a built-in cheat sheet, namely (http://regex101.com). Make sure you select Python on the left.\n",
    "\n",
    "<img src=\"./Illustrations/regex101.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# this regular expression should work, give it a try in regex101 \n",
    "# you can also try and modify it so you extract well column and well row separately\n",
    "regex = r\"(?P<basepath>.*)[/\\\\].*images_(?P<Plate>.*)w\\d[/\\\\](?P<Prefix>.*)_(?P<well>[A-Z]\\d\\d)_s(?P<subpos>\\d)_w(?P<Channel>\\d)(?P<ID>.*)\\.tif$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstimage = str(first_5_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = re.match(regex, firstimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = m.groupdict()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tmp[\"filename\"] = firstimage\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(tmp) # convert the dictionary to a pd.Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's assemble the individual steps we performed above into a single function.\n",
    "Given a filename and a regular expression the function should extract metadata using the regular expression\n",
    "and extract it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_metadata_as_series(filepath, regex, filename_key=\"filepath\"):\n",
    "    ''' \n",
    "    provided with a filepath (can be a string or a pathlib.PosixPath object),\n",
    "    tries to match the path against the regular expression regex.\n",
    "    The extracted keys, plus the filepath are returned as a pandas Series object\n",
    "    '''\n",
    "    if  type(filepath) == pathlib.PosixPath:\n",
    "        filepath = str(filepath)\n",
    "    m = re.match(regex, filepath)\n",
    "    if m is not None:\n",
    "        tmp = m.groupdict()\n",
    "        tmp[filename_key] = filepath\n",
    "        return pd.Series(tmp)\n",
    "    else:\n",
    "        print(f\"Extracting metadata for {filepath} failed.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can combine a list of multiple `pd.Series` objects into a `pd.DataFrame`. More on `DataFrames` later.\n",
    "\n",
    "Let's try with two series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s1 = get_metadata_as_series(first_5_files[1], regex)\n",
    "s2 = get_metadata_as_series(first_5_files[2], regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([s1, s2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Find all files and extract metadata\n",
    "\n",
    "Now let's create a data frame by analyzing all the filenames. \n",
    "There are several ways to do this: \n",
    "* You could use a for loop \n",
    "* You can use a `list comprehension`\n",
    "* You can use `map`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create a fresh generator, because we've \"used up\" the previous one\n",
    "files =  folder.rglob(\"*.tif\") \n",
    "# for each file, extract the metadata ... using a list comprehension\n",
    "metadata_series_list = [get_metadata_as_series(f, regex) for f in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now combine all metadata series objects into a **pandas** `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# there are many ways to create a DataFrame. Here we pass a list of pd.Series objects\n",
    "df_meta = pd.DataFrame(metadata_series_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Just evaluating a pandas DataFrame in a cell will provide a tabular output (abbreviated for long data frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can get some summary information for the data frame using `.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_meta.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you just want to get a quick feel for what kind of data is in a data frame, but you don't want to output a long frame use `.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interactive, sortable display of data frames using qgrid\n",
    "\n",
    "Notice how we only get a static, abbreviated output of the large data frame in the notebook.\n",
    "You can also display the dataframe in an interactive fashion using the qgrid package. To install, run\n",
    "```\n",
    "conda install -c conda-forge qgrid \n",
    "```\n",
    "Documentation and examples can be found at https://github.com/quantopian/qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import qgrid\n",
    "tablewidget = qgrid.show_grid(df_meta, show_toolbar=True)\n",
    "tablewidget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can actually edit the data frame with the qgrid widget and read back the contents into a data frame (see the documentatoin for details). \n",
    "\n",
    "This may be convenient, but from the perspective of reproducible data analysis such manual changes are not recommended unless you save your modified data frame, such that your changes can be reproduced from a file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "now we have already used `pd.Series` and `pd.DataFrame`, but ...\n",
    "\n",
    "# ... what is Pandas ?\n",
    "**Pandas** is a library that provides a `DataFrame` data structure and functions to work efficiently on this data structure. This is equivalent to a `DataFrame` or `tibble` in R. \n",
    "If you are not familiar with the concept of data frames, just think of it as an Excel table or a table in a relational database.\n",
    "\n",
    "## How does a Pandas DataFrame differ from a numpy array ?\n",
    "* `numpy` arrays are homogeneous, in the sense that they contain the same data type for each member of the array.\n",
    "* `numpy` arrays support `n`-dimensional data, where `n` can be larger than 2.\n",
    "* `pandas.DataFrame` objects can be heterogeneous, i.e. every column can hold a different object type. This includes non-numerical data.\n",
    "* `pandas.DataFrame` objects are essentially 2-dimensional\n",
    "\n",
    "\n",
    "## What do Pandas and numpy have in common ?\n",
    "\n",
    "* they have similar interfaces for working with the data. For example, you can perform operation such as `some_array.mean()` or `some_array.unique()` etc.\n",
    "* under the hood, a pandas dataframe uses numpy arrays to store the data\n",
    "\n",
    "\n",
    "## Why bother?\n",
    "\n",
    "You won't be storing images in pandas data frames, so why bother?\n",
    "\n",
    "Typically, the aim of your image analysis is to go from images to measurements, e.g. a list of objects and measured features for these objects. Pandas data frames are ideal data structures for storing and analysing such lists. \n",
    "Pandas data frames support grouping operations (`groupby`) that let you efficiently run operations on certain subsets of the data, following the [Split-Apply-Combine Pattern](https://www.jstatsoft.org/article/view/v040i01/v40i01.pdf)\n",
    "popularized by _Hadley Wickham_.\n",
    "For instance if you have a data table that holds measurements taken in multiple plates of a high-throughput-screen you can quickly calculate statistics on a per-plate level if you group by plate. [You can find more examples in the pandas documentation](http://pandas.pydata.org/pandas-docs/stable/groupby.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning Pandas\n",
    "There is not enough time to cover pandas in depth during this course. For an introduction from the ground up,\n",
    "check out Jake VanDerPlas's [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook).\n",
    "[Direct link to the pandas chapter](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.00-Introduction-to-Pandas.ipynb).\n",
    "\n",
    "Alternatively there are also notebooks available for Wes McKinney's book [Python for Data Analysis](https://github.com/wesm/pydata-book). \n",
    "[Chapter 5 introduces Pandas](http://nbviewer.jupyter.org/github/pydata/pydata-book/blob/2nd-edition/ch05.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's look which wells we have images from:\n",
    "df_meta[\"well\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# note: different way of referring to the column, an alternative to df_meta[\"subpos\"]\n",
    "df_meta.subpos.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Exporting/Importing a data frame\n",
    "\n",
    "* `.csv` files\n",
    "* `.json` files\n",
    "* `pickle`, `hdf5`, `sql`\n",
    "\n",
    "and system clipboard. \n",
    "You can try \n",
    "```\n",
    "df_meta.to_clipboard()\n",
    "```\n",
    "\n",
    "and using paste in Excel. \n",
    "Or try copying something in Excel and running\n",
    "\n",
    "```\n",
    "pd.read_clipboard()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We don't really need the columns ID, Prefix and basepath for our further analysis, so let's get rid of them\n",
    "df_meta.drop(columns=['ID', 'Prefix', 'basepath'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_meta # or use qgrid.show_grid(df_meta) for a more fancy output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DataFrame `groupby` method \n",
    "\n",
    "Our data frame has one row for each image file. However, some of these images clearly belong together, that is the images of the different fluorescence channels taken in the same _subposition_ of the same _well_ on the same _plate_.\n",
    "Therefore we want to group these images together. This can be done naturally using the `groupby()` method of the pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "groupby = df_meta.groupby([\"well\", \"subpos\", \"Plate\"])\n",
    "groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# one can iterate over groups\n",
    "for group in groupby:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# one can get the group keys\n",
    "keys = groupby.groups.keys()\n",
    "# show only the first few\n",
    "list(keys)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# access an individual group by key\n",
    "groupby.get_group(list(keys)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# pick a group as an example, here is randomly chose the group with index 8\n",
    "example_group = groupby.get_group(list(keys)[8])\n",
    "example_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# these happen to be sorted, already but to make sure we can do                                  \n",
    "example_group.sort_values(\"Channel\", ascending=True) # also try ascending=False to see that it is actually sorting                                  \n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# now just grab the filepaths\n",
    "example_group.sort_values(\"Channel\", ascending=True)[\"filepath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# but this is still a series, lets turn it into a list\n",
    "filelist = list(example_group.sort_values(\"Channel\", ascending=True)[\"filepath\"])\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# now we can read all of these images very quickly using a list comprehension or a map\n",
    "images = map(imread, filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Images is a `map` object. Similarly to generators the mapping is only evaluated when it is needed. \n",
    "We can force the evaluation (in this case reading the images) by converting it to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "images = list(images)\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's convert the list of numpy arrays into an _n_-dimensional array (n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_one = np.array(images)\n",
    "all_in_one.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interactive plotting and image viewing using holoviews/bokeh\n",
    "\n",
    "**Bokeh** is a plotting library similar to `matplotlib`. However, instead of generating static plots it generates plots as HTML-files with Javascript that can be embedded in the notebook and allow user interaction.\n",
    "\n",
    "**Holoviews** is a higher-level plotting library that can use **bokeh** and **matplotlib** as backened. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')  # without speciyfing the extension you won't see a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "imview = hv.Image(all_in_one[3,:,:]).options(tools=['hover'], cmap=\"gray\",width=696, height=520, colorbar=False)\n",
    "imview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With holoviews you can create an image viewer with a channel slider using their  `DynamicMap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_channel(c):\n",
    "    tmp = all_in_one[c,: , :]\n",
    "    size = tmp.shape\n",
    "    return  hv.Image(tmp).options(tools=['hover'], cmap=\"gray\", width=size[1], height=size[0])\n",
    "\n",
    "hv.DynamicMap(select_channel, kdims=['c',]).redim.values(c=range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now wrap this in a convenience function, so you can just run this on any image (note that in the cell above the callback  function referred directly to `all_in_one`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewer_with_channel(image_ch):\n",
    "    def select_ch(c):\n",
    "        tmp = image_ch[c,: , :]\n",
    "        size = tmp.shape\n",
    "        return  hv.Image(tmp).options(tools=['hover'], cmap=\"gray\", width=size[1], height=size[0])\n",
    "    \n",
    "    return(hv.DynamicMap(select_ch, kdims=['c',]).redim.values(c=range(image_ch.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "viewer_with_channel(all_in_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you are keen, you can also try to add additional sliders for adjusting the range, the colormap etc.\n",
    "Here is a rough cut piece of code that demonstrates this functionality:\n",
    "https://github.com/VolkerH/my_hv_gallery/blob/master/Images_with_interactors/Dynamic_map_interactor.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Build a simple image analysis pipeline\n",
    "\n",
    "* missing: Preprocessing (noise removal, illumination correction, background subraction)\n",
    "* Segment nuclei using OTSU\n",
    "* Split and label nuclei\n",
    "* Expand to find cytoplasm\n",
    "* missing: remove touching objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import skimage.filters # this module provides the otsu algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Segment Nuclei using thresholding.\n",
    "Determine the threshold value using Otsu's method of maximizing the inter-class variance. \n",
    "(https://en.wikipedia.org/wiki/Otsu's_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# TODO ... put the nuclear channel in im\n",
    "threshval = skimage.filters.threshold_otsu(im)\n",
    "threshval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "hv.Image(im > threshval).options(cmap=\"gray\",width=500, colorbar=True, tools=['hover'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Object splitting and connected component labelling\n",
    "\n",
    "The following function takes a binary image and tries to split adjacent nuclei using the distance transform and finding local maxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_label(thresholded_image, bc_size = (9,9)):\n",
    "    \n",
    "    '''split objects using distance transform and watershed\n",
    "    this implementation uses functions from the mahotas package\n",
    "    \n",
    "    You could also try to implement this using scikit-image and scipy.ndimage functions\n",
    "    such as scipy.ndimage.morphology.distance_transform_edt for the distance transform\n",
    "    and peak_local_max to find the regional maxima of the seed points\n",
    "    see for example here: scipy.ndimage.morphology.distance_transform_edt\n",
    "    ''' \n",
    "    distances = mahotas.stretch(mahotas.distance(thresholded_image)) # you could try using \n",
    "    Bc = np.ones(bc_size) \n",
    "    maxima = mahotas.morph.regmax(distances, Bc=Bc) # you could try adapting this to s\n",
    "    spots, n_spots = mahotas.label(maxima) #, Bc=Bc)\n",
    "    surface = (distances.max() - distances)\n",
    "    areas = mahotas.cwatershed(surface, spots)\n",
    "    areas *= thresholded_image\n",
    "    return(areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# todo \n",
    "\n",
    "# try segmenting the nuclei using otsu and split and label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Finding the cytoplasm\n",
    "\n",
    "Once you have the nuclei as seed points, you can use several methods to grow these seed regions to find the surrounding cytoplasm. There are a number of commonly used techniques, for example, CellProfiler provides the following techniques:\n",
    "\n",
    "* watershed\n",
    "* seeded region growing\n",
    "* distance-N\n",
    "\n",
    "Unless you have a marker that clearly delineates the cell boundary or marks the whole cytoplasm, you should use distance-N, otherwise you might bias your results (interactive whiteboard: explain why)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def distanceN(labels_in, distance):\n",
    "    '''\n",
    "    Distance-N implementation \n",
    "    Taken/adapted from the CellProfiler source code for their IdentifySecondaryObjects\n",
    "    module.\n",
    "    \n",
    "    The basic idea is that you have some seed labels (in the context \n",
    "    of cell profiling these will typically be cell nuclei) that you want \n",
    "    to grow by n pixels to give a mask for a larger object (the cytoplasm).\n",
    "    \n",
    "    If you were only dealing with a single seed object, you could simply dilate with \n",
    "    a suitably sized structuring element. However, in general you have multiple seed \n",
    "    points and you don't want to merge those. Distance N will grow up to N pixels without\n",
    "    merging objects that are closer together than 2N. \n",
    "    ''' \n",
    "    \n",
    "    tmp = scipy.ndimage.morphology.distance_transform_edt(labels_in == 0, return_indices = True)\n",
    "    distances, (i,j) = tmp\n",
    "    labels_out = np.zeros(labels_in.shape, int)\n",
    "    dilate_mask = distances <= distance\n",
    "    labels_out[dilate_mask] = labels_in[i[dilate_mask],j[dilate_mask]]\n",
    "    return labels_out    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature extraction for the cell regions in each channel\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Read the documentation of [`skimage.measure`](http://scikit-image.org/docs/dev/api/skimage.measure.html), in particular `regionprops`.\n",
    "* Apply `regionprops` using a label image and a greyvalue image\n",
    "* Try and make sense of the output\n",
    "* assemble into a data frame\n",
    "* save a crop or thumbnail for each segmented cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
