{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CellProfiling  in Python\n",
    "\n",
    "A high-throughput screening analysis pipeline, similar to what you would do in CellProfiler, implemented in Python.\n",
    "\n",
    "Aims: \n",
    "\n",
    "* create an image analysis pipeline for batch processing, somewhat similar to running Cellprofiler\n",
    "* do some statistical analysis and create interactive visualizations using holoviews\n",
    "* introduce pandas data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# High Throughput Screening Workflow\n",
    "\n",
    "<img src=\"./Illustrations/HTMPipeline_alt.png\" height=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sample images\n",
    "Images are a subset of dataset BBBC022 from the [Broad Bioimage Benchmark Collection](https://data.broadinstitute.org/bbbc/)\n",
    "\n",
    "The following description of the dataset is from their website (https://data.broadinstitute.org/bbbc/BBBC022/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pathlib\n",
    "import re\n",
    "import numpy as np\n",
    "import mahotas # see other Image Analysis Packages !\n",
    "import scipy.ndimage.morphology\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "# Alternative\n",
    "#from tifffile import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Find and load the images\n",
    "\n",
    "same as last week, just removed some comments\n",
    "\n",
    "## Don't forget to change the base folder  in the next cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Set our base folder (adjust this to the path where your images are)\n",
    "folder = pathlib.Path(\"/Users/volker/Downloads/BroadData/for_course/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extracting Metadata from Path/File names with regular expressions\n",
    "\n",
    "In many cases, you will find some Metadata that is related to your screen embedded in the file names of the images.\n",
    "Therefore we need to extract this information from the images we analyze.\n",
    "\n",
    "_Regular expressions_ are a flexible tool for analyzing/splitting strings that are built according to some regular pattern. If you google for \"python regular expressions\" you will find plenty of documentation and examples on how to use them. \n",
    "\n",
    "As regular expressions have a large number of building blocks that may be difficult to remember, it is nice to have a cheat sheet. There is a great online tool for creating and debugging regular expressions with a built-in cheat sheet, namely [regex101](http://regex101.com ). Make sure you select Python on the left.\n",
    "\n",
    "<img src=\"./Illustrations/regex101.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# this regular expression should work, give it a try in regex101 \n",
    "# you can also try and modify it so you extract well column and well row separately\n",
    "regex = r\"(?P<basepath>.*)[/\\\\].*images_(?P<Plate>.*)w\\d[/\\\\](?P<Prefix>.*)_(?P<well>[A-Z]\\d\\d)_s(?P<subpos>\\d)_w(?P<Channel>\\d)(?P<ID>.*)\\.tif$\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_metadata_as_series(filepath, regex, filename_key=\"filepath\"):\n",
    "    ''' \n",
    "    provided with a filepath (can be a string or a pathlib.PosixPath object),\n",
    "    tries to match the path against the regular expression regex.\n",
    "    The extracted keys, plus the filepath are returned as a pandas Series object\n",
    "    '''\n",
    "    filepath = str(filepath)\n",
    "    m = re.match(regex, filepath)\n",
    "    if m is not None:\n",
    "        tmp = m.groupdict()\n",
    "        tmp[filename_key] = filepath\n",
    "        return pd.Series(tmp)\n",
    "    else:\n",
    "        print(f\"Extracting metadata for {filepath} failed.\")\n",
    "        return None\n",
    "    \n",
    "#get_metadata_as_series(firstimage, regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Find all files and extract metadata\n",
    "\n",
    "Now let's create a data frame by analyzing all the filenames. \n",
    "There are several ways to do this: \n",
    "* You could use a for loop \n",
    "* You can use a `list comprehension`\n",
    "* You can use `map`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# find files\n",
    "files =  folder.rglob(\"*.tif\") \n",
    "# for each file, extract the metadata ... using a list comprehension\n",
    "metadata_series_list = [get_metadata_as_series(f, regex) for f in files]\n",
    "metadata_series_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now combine all metadata series objects into a **pandas** `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# there are many ways to create a DataFrame. Here we pass a list of pd.Series objects\n",
    "df_meta = pd.DataFrame(metadata_series_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_meta.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you just want to get a quick feel for what kind of data is in a data frame, but you don't want to output a long frame use `.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning Pandas\n",
    "There is not enough time to cover pandas in depth during this course. For an introduction from the ground up,\n",
    "check out Jake VanDerPlas's [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook).\n",
    "[Direct link to the pandas chapter](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.00-Introduction-to-Pandas.ipynb).\n",
    "\n",
    "Alternatively there are also notebooks available for Wes McKinney's book [Python for Data Analysis](https://github.com/wesm/pydata-book). \n",
    "[Chapter 5 introduces Pandas](http://nbviewer.jupyter.org/github/pydata/pydata-book/blob/2nd-edition/ch05.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# note: different way of referring to the column, an alternative to df_meta[\"subpos\"]\n",
    "df_meta[\"subpos\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Refresher**\n",
    "\n",
    "Exporting/Importing a data frame\n",
    "\n",
    "* `.csv` files `df.to_csv`, `pd.read_csv`\n",
    "* `.json` files `df.to_json`, `pd.read_json`\n",
    "* `pickle`, `hdf5`, `sql` using similar function/method names `...`\n",
    "\n",
    "\n",
    "You can also work with the system clipboard. \n",
    "You can try \n",
    "```\n",
    "df_meta.to_clipboard()\n",
    "```\n",
    "\n",
    "and using paste in Excel. \n",
    "Or try copying something in Excel and running\n",
    "\n",
    "```\n",
    "pd.read_clipboard()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We don't really need the columns ID, Prefix and basepath for our further analysis, so let's get rid of them\n",
    "df_meta.drop(columns=['ID', 'Prefix', 'basepath'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DataFrame `groupby` method \n",
    "\n",
    "Our data frame has one row for each image file. However, some of these images clearly belong together, that is the images of the different fluorescence channels taken in the same _subposition_ of the same _well_ on the same _plate_.\n",
    "Therefore we want to group these images together. This can be done naturally using the `groupby()` method of the pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "groupby = df_meta.groupby([\"well\", \"subpos\", \"Plate\"])\n",
    "# one can get the group keys\n",
    "keys = groupby.groups.keys()\n",
    "# show only the first few\n",
    "list(keys)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# access an individual group by key\n",
    "groupby.get_group(list(keys)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# pick a group as an example, here I randomly chose the group with index 8\n",
    "example_group = groupby.get_group(list(keys)[8])\n",
    "example_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create a file list from the group\n",
    "filelist = list(example_group.sort_values(\"Channel\", ascending=True)[\"filepath\"])\n",
    "# read all files using a list comprehension ... reminder, you could also use the `map` function\n",
    "images = [imread(f) for f in filelist] \n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "type(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's convert the list of numpy arrays into an _n_-dimensional array (n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_one = np.array(images)\n",
    "all_in_one.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interactive plotting and image viewing using holoviews/bokeh\n",
    "\n",
    "**Bokeh** is a plotting library similar to `matplotlib`. However, instead of generating static plots it generates plots as HTML-files with Javascript that can be embedded in the notebook and allow user interaction.\n",
    "**plot.ly **\n",
    "\n",
    "**Seaborn**\n",
    "\n",
    "**Holoviews** is a higher-level plotting library that can use **bokeh** and **matplotlib** as backened. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')  # without speciyfing the extension you won't see a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "imview = hv.Image(all_in_one[3,:,:]).options(tools=['hover'], cmap=\"gray\",width=700, height=500, colorbar=False)\n",
    "imview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With holoviews you can create an image viewer with a channel slider using their  `DynamicMap`.\n",
    "\n",
    "Here, we create a convenience function for it:\n",
    "\n",
    "(Note that we define a function in a function ... you can do this in python !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewer_with_channel(image_ch):\n",
    "    def select_ch(c):\n",
    "        tmp = image_ch[c,: , :]\n",
    "        size = tmp.shape\n",
    "        return  hv.Image(tmp).options(tools=['hover'], cmap=\"gray\", width=size[1], height=size[0])\n",
    "    \n",
    "    return(hv.DynamicMap(select_ch, kdims=['c',]).redim.values(c=range(image_ch.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "viewer_with_channel(all_in_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some more holoviews tricks: Add plots/images to layout  with +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More information about holoviews layouting at http://holoviews.org/user_guide/Composing_Elements.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you are keen, you can also try to add additional sliders for adjusting the range, the colormap etc.\n",
    "Here is a rough cut piece of code that demonstrates this functionality:\n",
    "https://github.com/VolkerH/my_hv_gallery/blob/master/Images_with_interactors/Dynamic_map_interactor.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Build a simple image analysis pipeline\n",
    "\n",
    "* missing: Preprocessing (noise removal, illumination correction, background subraction)\n",
    "* Segment nuclei using OTSU\n",
    "* Split and label nuclei\n",
    "* Expand to find cytoplasm\n",
    "* missing: remove touching objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import skimage.filters # this module provides the otsu algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Segment Nuclei using thresholding.\n",
    "Determine the threshold value using Otsu's method of maximizing the inter-class variance. \n",
    "(https://en.wikipedia.org/wiki/Otsu's_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#  put the nuclear channel in variable im\n",
    "im = all_in_one[0, : , :]\n",
    "threshval = skimage.filters.threshold_otsu(im)\n",
    "threshval\n",
    "hv.Image(im > threshval).options(cmap=\"gray\",width=700, height=500, tools=['hover'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Object splitting and connected component labelling\n",
    "\n",
    "The following function takes a binary image and tries to split adjacent nuclei using the distance transform and finding local maxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_label(thresholded_image, bc_size = (9,9)):\n",
    "    \n",
    "    '''split objects using distance transform and watershed\n",
    "    this implementation uses functions from the mahotas package\n",
    "    \n",
    "    You could also try to implement this using scikit-image and scipy.ndimage functions\n",
    "    such as scipy.ndimage.morphology.distance_transform_edt for the distance transform\n",
    "    and peak_local_max to find the regional maxima of the seed points\n",
    "    see for example here: scipy.ndimage.morphology.distance_transform_edt\n",
    "    ''' \n",
    "    distances = mahotas.stretch(mahotas.distance(thresholded_image)) # you could try using \n",
    "    Bc = np.ones(bc_size) \n",
    "    maxima = mahotas.morph.regmax(distances, Bc=Bc) # you could try adapting this to s\n",
    "    spots, n_spots = mahotas.label(maxima, Bc=Bc)\n",
    "    surface = (distances.max() - distances)\n",
    "    areas = mahotas.cwatershed(surface, spots)\n",
    "    areas *= thresholded_image\n",
    "    return(areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from skimage.morphology import opening, opening, disk \n",
    "\n",
    "def find_nuclei(im, bc_size=(20,20), opening_disk_radius=4):\n",
    "    '''Segment nuclei by using otsu thresholding. Fills holes, splits and labels.'''\n",
    "    threshval = skimage.filters.threshold_otsu(im)\n",
    "    tmp = binary_fill_holes(im > threshval)\n",
    "    labelled = split_and_label(tmp, bc_size)\n",
    "    labelled = opening(labelled,disk(opening_disk_radius)) # remove small isolated bits\n",
    "    return(labelled)\n",
    "\n",
    "labelled = find_nuclei(im)\n",
    "hv.Image(labelled).options(cmap=\"flag\", tools=['hover'], width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Expanding to the cytoplasm\n",
    "\n",
    "Once you have the nuclei as seed points, you can use several methods to grow these seed regions to find the surrounding cytoplasm. There are a number of commonly used techniques, for example, CellProfiler provides the following techniques:\n",
    "\n",
    "* watershed\n",
    "* seeded region growing\n",
    "* distance-N\n",
    "\n",
    "Unless you have a marker that clearly delineates the cell boundary or marks the whole cytoplasm, you should use distance-N, otherwise you might bias your results (interactive whiteboard: explain why)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def distanceN(labels_in, distance):\n",
    "    '''\n",
    "    Distance-N implementation \n",
    "    Taken/adapted from the CellProfiler source code for their IdentifySecondaryObjects\n",
    "    module.\n",
    "    \n",
    "    The basic idea is that you have some seed labels (in the context \n",
    "    of cell profiling these will typically be cell nuclei) that you want \n",
    "    to grow by n pixels to give a mask for a larger object (the cytoplasm).\n",
    "    \n",
    "    If you were only dealing with a single seed object, you could simply dilate with \n",
    "    a suitably sized structuring element. However, in general you have multiple seed \n",
    "    points and you don't want to merge those. Distance N will grow up to N pixels without\n",
    "    merging objects that are closer together than 2N. \n",
    "    ''' \n",
    "    \n",
    "    tmp = scipy.ndimage.morphology.distance_transform_edt(labels_in == 0, return_indices = True)\n",
    "    distances, (i,j) = tmp\n",
    "    labels_out = np.zeros(labels_in.shape, int)\n",
    "    dilate_mask = distances <= distance\n",
    "    labels_out[dilate_mask] = labels_in[i[dilate_mask],j[dilate_mask]]\n",
    "    return labels_out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cytolabel = distanceN(labelled, 30)\n",
    "hv.Image(cytolabel).options(cmap=\"flag\", tools=['hover'], width=700,height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Remove Cells touching the image boundary\n",
    "\n",
    "These cells are not fully in the image, so if we calculate properties we may get misleading results.\n",
    "\n",
    "`skimage` provides the `clear_border` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.segmentation import clear_border\n",
    "\n",
    "cyto_no_border = clear_border(cytolabel)\n",
    "hv.Image(cyto_no_border).options(cmap=\"flag\", tools=['hover'], width=700,height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the nuclei ?\n",
    "\n",
    "We should remove the nuclei corresponding to the cells we removed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the region labels reamaining after clear_border \n",
    "remaining_labels = np.unique(cyto_no_border) \n",
    "remaining_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Check which of the original nuclei labels are in remaining_labels\n",
    "# Note that this code is backward-compatible with older numpy versions... newer versions have np.isin \n",
    "remaining_mask = np.in1d(labelled, remaining_labels)\n",
    "remaining_mask = remaining_mask.reshape(labelled.shape)\n",
    "remaining_nuclei = labelled * remaining_mask\n",
    "hv.Image(remaining_nuclei).options(cmap=\"flag\", tools=['hover'], width=700,height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# check cytoplasm\n",
    "hv.Image(cyto_no_border-remaining_nuclei).options(cmap=\"flag\", tools=['hover'], width=700,height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practice session (about 10 minutes):\n",
    "\n",
    "Combine the above code cells into a single function\n",
    "`segment_image(input)` that \n",
    "takes an image of fluorescenlty labelled nuclei as input\n",
    "and performs a segmentation of the nuclei and the cells. \n",
    "\n",
    "It should return a python dictionary of the form\n",
    "\n",
    "```\n",
    "{ \"nuclei\" : label_image_nuclei\n",
    "  \"cells\" : cells\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p>\n",
    ".\n",
    "<p>\n",
    ".\n",
    "<p>\n",
    ".\n",
    "<p>\n",
    ".\n",
    "<p>\n",
    ".\n",
    "<p>\n",
    ".\n",
    "<p>\n",
    "\n",
    "\n",
    "\n",
    "# Solution: \n",
    "\n",
    "You can find a possible solution in the next cell (that one contains additional error checking), but try not to skip ahead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def segment_image(im):\n",
    "    '''\n",
    "    Takes an image of fluorescenly labelled nuclei as input im\n",
    "    and performs the following segmentation steps\n",
    "    * Threshold using Otsu\n",
    "    * Fill small holes\n",
    "    * Split clumps using distance transform and watershed seeded from local maxima\n",
    "    * Label image\n",
    "    * Remove small objects with an opening \n",
    "    * Use distance - N to expand to cell region\n",
    "    * Remove cell region label components that touch the image boundary\n",
    "    * Create a new label image for the nuclei without the nuclei corresponding to cells that touched the boundary\n",
    "    * returns the masks as a dictionary\n",
    "    '''\n",
    "    initial_nuclei = find_nuclei(im)\n",
    "    initial_cells = distanceN(initial_nuclei, 30)\n",
    "    cells = clear_border(initial_cells)\n",
    "    remaining_labels = np.unique(cells)\n",
    "    remaining_mask =  np.in1d(initial_nuclei, remaining_labels)\n",
    "    remaining_mask = remaining_mask.reshape(initial_nuclei.shape)\n",
    "    nuclei = initial_nuclei * remaining_mask\n",
    "    \n",
    "    # sanity check:\n",
    "    # make sure we only retain labels that are in both masks\n",
    "    labels_n = set(np.unique(nuclei))\n",
    "    labels_c = set(np.unique(cells))\n",
    "    \n",
    "    difference = labels_n.symmetric_difference(labels_c)\n",
    "    if bool(difference):\n",
    "        print(\"Warning, sets differ by labels \", sorted(list(difference)))\n",
    "        print(\"Nuclei\", sorted(list(labels_n)))\n",
    "        print(\"cells\", sorted(list(labels_c)))\n",
    "    \n",
    "    return({\"nuclei\": nuclei, \n",
    "            \"cells\": cells,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = segment_image(im)\n",
    "hv.Image(masks[\"cells\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How would you improve the `segment_image` function ?\n",
    "\n",
    "\n",
    "* suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature extraction for the cell regions in each channel\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Read the documentation of [`skimage.measure`](http://scikit-image.org/docs/dev/api/skimage.measure.html), in particular `regionprops`.\n",
    "* Apply `regionprops` using a label image and a greyvalue image\n",
    "* Try and make sense of the output\n",
    "* assemble into a data frame\n",
    "* save a crop or thumbnail for each segmented cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Interactive analysis of skimage.regionprops output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  DataFrame reformatting and combining with Broad Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rearrange datatable \n",
    "\n",
    "Such that filenames referring to different channels of the same field of view appear in a single row.\n",
    "As a result, each row will refer to a single position. \n",
    "\n",
    "We are going to use `groupby` and `unstack`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# remind ourselves of the structure of the data frame\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*  Group all dimensions other than filepath using `groupby`.\n",
    "* use appply to apply a helper function to each group\n",
    "* the helper function simply returns the value of the column filepath using `item()` (note that you sometimes get back an object with an index)\n",
    "* finally, `unstack()` takes the values and turns them into columns.\n",
    "\n",
    "Needing to call a helper function to simply return a column value seems unnecessarily complicated, there must be an easier way (I haven't found it :-( ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retfp(d):\n",
    "    \"\"\"\n",
    "    helper function that returns the value of the filepath column for dataframe d.\n",
    "    \"\"\"\n",
    "    return d[\"filepath\"].item()\n",
    "wide = df_meta.groupby([\"Plate\", \"well\", \"subpos\", \"Channel\"]).apply(retfp).unstack()\n",
    "wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The column names are not that nice, so we create new ones and assign them to the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names  = [\"Channel_\"+cn for cn in wide.columns]\n",
    "new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide.columns = new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We still need to remove the multi index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = wide.reset_index(level=[\"Plate\",\"well\", \"subpos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Changing data types from object to integer\n",
    "During last session we noticed that some columns were having the generic data type object, although they were essentially numeric. \n",
    "One way to fix this is with `.astype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide[\"subpos\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wide = wide.astype({\"subpos\":np.int})\n",
    "wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This didn't work last time\n",
    "wide.subpos.mean()\n",
    "# now it does (at least in my notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Merging our data frame with the compound information from the Broad Institute \n",
    "\n",
    "* The Broad Institute provides a `.csv` file data frame has information about the compounds, which we want for our downstream analysis and plotting.\n",
    "* The csv-file can be downloaded from  https://data.broadinstitute.org/bbbc/BBBC022/BBBC022_v1_image.csv\n",
    "\n",
    "* We want to keep all rows from the data frame we created based on the metadate extracted from the filenames, but add a few meaningful columns from the Broad data frame.\n",
    "* We want to find a unique identifier for each field, based on which we can merg. We can do this on the filename for channel 1 for example (this should be unique).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Load and explore the data frame provided by the Broad Institute\n",
    "\n",
    "\n",
    "\n",
    "Read it with pandas `pd.read_csv`.\n",
    "\n",
    "It appears the `.csv` file is corrupt, therefore we need to set `error_bad_lines` to `False` so we can skip over bad lines.\n",
    "(there seems to be a problem with delimiters in the file, I haven't had time to look into the exact problem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can download the file in the notebook (makes it more reproducible for others)\n",
    "\n",
    "#from urllib.request import urlretrieve\n",
    "#urlretrieve(\"https://data.broadinstitute.org/bbbc/BBBC022/BBBC022_v1_image.csv\", \"BBBC022_v1_image.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "broaddf = pd.read_csv(\"BBBC022_v1_image.csv\", error_bad_lines=True, warn_bad_lines=True)\n",
    "broaddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Look at the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broaddf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create a new data frame with just the columns that are of interest to us:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_interesting_cols_df = broaddf[[\"Image_FileName_OrigHoechst\",\"Image_Metadata_CPD_MMOL_CONC\", \"Image_Metadata_ASSAY_WELL_ROLE\", \"Image_Metadata_SOURCE_COMPOUND_NAME\", 'Image_Metadata_SOURCE_NAME']]\n",
    "broad_interesting_cols_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `wide` data frame we created from the list of files and their metadata has the full path name. \n",
    "If we want to merge the two data frames based on the file name for the Hoeschst image, we need to add a file name  column to  the `wide` data frame.\n",
    "\n",
    "Extract the filename from a path (one approach would be to use `os.path.split(filename)`.\n",
    "With `pathlib` we first convert the string into a `Path` object and then use the `.name` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# just to seeh how this works\n",
    "ptmp = pathlib.Path(wide.Channel_1[0])\n",
    "ptmp.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using `apply` we can apply a function to extract the filename from the full path to a full column. \n",
    "\n",
    "We assign the result to a new column that has the same name as the corresponding column in the Broad data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide[\"Image_FileName_OrigHoechst\"] = wide.Channel_1.apply(lambda x: pathlib.Path(x).name)\n",
    "wide[\"Image_FileName_OrigHoechst\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Merge the two data frames based on the `Image_FileName_OrigHoechst` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(wide, broad_interesting_cols_df, on=\"Image_FileName_OrigHoechst\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Processing rows in the image data frame\n",
    "\n",
    "For each row in the data table, we want to do the following\n",
    "\n",
    "* read all channels\n",
    "* segment to find nuclear and cytoplasm regions\n",
    "* calculate region properties for each combination of region and channel\n",
    "* create a new data frame where each row represents one cell and the columns represent existing metadata and the numerical features we extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read images for one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(files):\n",
    "    '''given a list of filename, reads them using the providef imread function and returns a numpy array'''\n",
    "    images = map(skimage.io.imread, files)\n",
    "    cyx_im = np.array(list(images)) # channel, y, x ordered numpy array\n",
    "    return(cyx_im)\n",
    "    \n",
    "def read_all_channels(row):\n",
    "    ''' Given a row of a data frame (as a Series object), \n",
    "    reads all images referred to by filenames in columns containing\n",
    "    \"Channel\" '''\n",
    "    files = filter(lambda x: 'Channel' in x, row.keys())\n",
    "    return read_files(row[files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_with_channel(read_all_channels(merged_df.iloc[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Processing rows in the image data frame\n",
    "\n",
    "For each row in the data table, we want to do the following\n",
    "\n",
    "* read all channels\n",
    "* segment to find nuclear and cytoplasm regions\n",
    "* calculate region properties for each combination of region and channel\n",
    "* create a new data frame where each row represents one cell and the columns represent existing metadata and the numerical features we extract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to translate integer channel index of numpy array into a meaningful_name\n",
    "channel_dict = {\n",
    "                0: \"Hoechst\",\n",
    "                1: \"conA\",\n",
    "                2: \"Syto\",\n",
    "                3: \"PhaWGA\",\n",
    "                4: \"Mito\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    " def calc_features(masks, im, channel_dict, verbose=False):\n",
    "    '''\n",
    "    calculates region properties for each mask (dictionary of label images) and channel in image im [ch,y,x].\n",
    "    channeldict is a dictionary that will assign a name to each channel number.\n",
    "    '''\n",
    "    nc, ny, nx = im.shape\n",
    "    props = {}\n",
    "    \n",
    "    for maskname, mask in masks.items():\n",
    "        if verbose:\n",
    "            print(\"Processing region mask \", maskname)\n",
    "        ch_props = {}\n",
    "        for ch in range(nc): \n",
    "            ch_name = channel_dict[ch]\n",
    "            if verbose:\n",
    "                print(\"    calulating region props for channel\", ch_name)           \n",
    "            ch_props[ch_name] = skimage.measure.regionprops(mask, im[ch,:,:])        \n",
    "        props[maskname] = ch_props\n",
    "    return(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ignore_props= ['convex_image', 'coords', 'filled_image', 'image']\n",
    "def unravel_features(features, ignore = ignore_props):\n",
    "    '''\n",
    "    unravels features calculated with calc_features to produce a data_frame with rows representing cells\n",
    "    and columns representing features.\n",
    "    \n",
    "    produces a dictionary with the following keys\n",
    "    '''\n",
    "    label_features = {}\n",
    "    for mask in features.keys():\n",
    "        for channel in features[mask].keys():\n",
    "            for region in features[mask][channel]:\n",
    "                prefix = f\"{region.label}_{channel}_{mask}_\"\n",
    "                # print(prefix)\n",
    "                for prop in region:\n",
    "                    if not prop in ignore_props:\n",
    "                        tmp = region[prop]\n",
    "                        #print(prop, type(tmp))\n",
    "                        \n",
    "                        # Commenting code\n",
    "                        #\n",
    "                        # bad comment: \"if it is an array make it flat\" \n",
    "                        # this comment duplicates the code in words, avoid such comments\n",
    "                        #\n",
    "                        # better comment: \"flatten so we can later iterate over all elements easily\"\n",
    "                        # this comment documents the intent behind the code\n",
    "                        if type(tmp) is np.ndarray:\n",
    "                            tmp = tmp.flatten()\n",
    "                        \n",
    "                        # I don't know of an easy way to test whether we can iterate over\n",
    "                        # an unknown object. With the try / except we simply try to do it \n",
    "                        # and catch the error if isn't possible.\n",
    "                        \n",
    "                        try: \n",
    "                            for i, value in enumerate(tmp):\n",
    "                                num = str(i).zfill(3) \n",
    "                                label_features[prefix+prop+\"_\"+num] = value\n",
    "                                #print(f\"{prop}_{num}: {value}\")\n",
    "                        except TypeError:\n",
    "                            label_features[prefix+prop] = tmp\n",
    "    return(label_features)\n",
    "    \n",
    "def generate_thumbnails(features, im, channel_dict, prefix, path):\n",
    "    '''\n",
    "    Given \n",
    "    features = \n",
    "    im = ndarray of shape [n_channels,ny,nx]\n",
    "    prefix\n",
    "    path \n",
    "    '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_feature_dict(fd, col_prefix=\"num_\"):\n",
    "    ''' \n",
    "    given a feature dict with keys of the form label_featurename\n",
    "    creates a DataFrame with a row for each label and a column for each feature.\n",
    "    The feature name columns will be prepended with the prefix col_prefix\n",
    "    '''\n",
    "    keys = fd.keys()\n",
    "    # find all region labels (alternatively we could pass the known labels to the function)\n",
    "    tmp = [int(k.split(\"_\",1)[0]) for k in keys]\n",
    "    labels = sorted(np.unique(tmp))\n",
    "    rows = {}\n",
    "    for l in labels:\n",
    "        # only the feature keys for the region l\n",
    "        featurekeys = list(filter(lambda x: x.startswith(str(l)+\"_\"),keys))\n",
    "        values = [fd[f] for f in featurekeys]\n",
    "        shortened_featurekeys = [col_prefix + f.split(\"_\",1)[1] for f in featurekeys]\n",
    "        row = pd.Series(data=values, index=shortened_featurekeys)\n",
    "        rows[l] = row\n",
    "    df = pd.DataFrame(rows)\n",
    "    return(df)\n",
    "\n",
    "def process_image_table_row(row, channel_dict):\n",
    "    '''\n",
    "    Processes a single row of an image table:\n",
    "    \n",
    "    1. Reads all the .tif files for the individual channels\n",
    "    2. Segments nuclei, cells\n",
    "    3. Calculates regionprops for each combination of channel and object mask (nuclei, cells)\n",
    "    4. Unravels the regionprops and turns it into a tidy DataFrame with one row per cell\n",
    "    5. (not yet implemented: generates thumbnails)\n",
    "    '''\n",
    "    im = read_all_channels(row)\n",
    "    masks = segment_image(im[0]) # dapi channel is channel 0\n",
    "    labels = np.unique(masks[\"nuclei\"])\n",
    "    features = calc_features(masks, im, channel_dict)\n",
    "    feature_dict = unravel_features(features)\n",
    "    df = df_from_feature_dict(feature_dict)\n",
    "    df = df.T\n",
    "    # create a unique index for each cell across the screen\n",
    "    # build this as platename_well_subpos_label\n",
    "    index_prefix = \"_\".join((row[\"Plate\"],row[\"well\"],row[\"subpos\"]))\n",
    "    df.index = [index_prefix + str(i) for i in df.index]\n",
    "    \n",
    "    # add columns from row so we have all the interesting metadata for each cell as well\n",
    "    for name in row.index:\n",
    "        if not name.startswith(\"Channel_\"):\n",
    "            df[name] = row[name]\n",
    "    \n",
    "    generate_thumbnails(features, im, channel_dict)\n",
    "    return({\"masks\": masks, \"features\":features, \"df\" : df})\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = merged_df.iloc[:5]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_props = process_image_table_row(merged_df.iloc[3], channel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def process_image_table(df, channel_dict):\n",
    "    cell_dfs = []\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "        tmp = process_image_table_row(row, channel_dict)\n",
    "        cell_dfs.append(tmp[\"df\"].T.drop_duplicates().T)\n",
    "    #df = pd.concat(cell_dfs)\n",
    "    # many of the features describing the shape are identical \n",
    "    # for all channels. Therefore we end up with duplicate\n",
    "    # columns which we can safely eliminate.\n",
    "    # Note that drop_duplicates removes duplicate rows, therefore\n",
    "    # we need to transpose twice\n",
    "    return cell_dfs #.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ptb = process_image_table(merged_df, channel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat(ptb)\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
